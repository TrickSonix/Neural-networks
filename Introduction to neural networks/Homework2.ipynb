{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images.\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5\n",
    "\n",
    "# Flatten the images.\n",
    "train_images = train_images.reshape((-1, 784))\n",
    "test_images = test_images.reshape((-1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.3760 - accuracy: 0.8876\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.1913 - accuracy: 0.9420\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.1476 - accuracy: 0.9547\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.1234 - accuracy: 0.9610\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.1078 - accuracy: 0.9660\n",
      "10000/10000 [==============================] - 0s 20us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11804294485226273, 0.9634000062942505]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(64, activation='relu', input_shape=(784,)),\n",
    "  Dense(64, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=5,\n",
    "  batch_size=32,\n",
    ")\n",
    "\n",
    "# Evaluate the model.\n",
    "model.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем увеличить кол-во эпох."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.3631 - accuracy: 0.8908\n",
      "Epoch 2/7\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.1902 - accuracy: 0.9427\n",
      "Epoch 3/7\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.1448 - accuracy: 0.9554\n",
      "Epoch 4/7\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.1247 - accuracy: 0.9614\n",
      "Epoch 5/7\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.1106 - accuracy: 0.9648\n",
      "Epoch 6/7\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.0967 - accuracy: 0.9694\n",
      "Epoch 7/7\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.0901 - accuracy: 0.9713\n",
      "10000/10000 [==============================] - 0s 25us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13241413424229248, 0.9591000080108643]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(64, activation='relu', input_shape=(784,)),\n",
    "  Dense(64, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=7,\n",
    "  batch_size=32,\n",
    ")\n",
    "\n",
    "# Evaluate the model.\n",
    "model.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, точность упала - модель слегка переобучилась."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем увеличить кол-во нейронов в каждом слое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.3517 - accuracy: 0.8949\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1814 - accuracy: 0.9457\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1380 - accuracy: 0.9578\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1144 - accuracy: 0.9647\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0994 - accuracy: 0.9691\n",
      "10000/10000 [==============================] - 0s 23us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10171364394016563, 0.9666000008583069]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(74, activation='relu', input_shape=(784,)),\n",
    "  Dense(74, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=5,\n",
    "  batch_size=32,\n",
    ")\n",
    "\n",
    "# Evaluate the model.\n",
    "model.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность немного возрасла."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем изменить функцию активации у некоторых слоев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.5652 - accuracy: 0.8561\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.2291 - accuracy: 0.9325\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.1703 - accuracy: 0.9497\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.1339 - accuracy: 0.9605\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.1131 - accuracy: 0.9663\n",
      "10000/10000 [==============================] - 0s 25us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13725836685821413, 0.9575999975204468]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(64, activation='sigmoid', input_shape=(784,)),\n",
    "  Dense(64, activation='sigmoid'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=5,\n",
    "  batch_size=32,\n",
    ")\n",
    "\n",
    "# Evaluate the model.\n",
    "model.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сигмоида хуже справляется с задачей нежели relu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем добавить еще один слой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.3448 - accuracy: 0.8928\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.1766 - accuracy: 0.9452\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.1415 - accuracy: 0.9553\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.1203 - accuracy: 0.9620\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.1054 - accuracy: 0.9677\n",
      "10000/10000 [==============================] - 1s 133us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10592387998532504, 0.9656000137329102]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(64, activation='relu', input_shape=(784,)),\n",
    "  Dense(64, activation='relu'),\n",
    "  Dense(64, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=5,\n",
    "  batch_size=32,\n",
    ")\n",
    "\n",
    "# Evaluate the model.\n",
    "model.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность модели немного возрасла по сравнению с исходной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем добваить нейронов и новый слой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.3337 - accuracy: 0.8970\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1652 - accuracy: 0.9491\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1313 - accuracy: 0.9592\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1102 - accuracy: 0.9650\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0966 - accuracy: 0.9696\n",
      "10000/10000 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10811293295091018, 0.9653000235557556]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(80, activation='relu', input_shape=(784,)),\n",
    "  Dense(80, activation='relu'),\n",
    "  Dense(80, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=5,\n",
    "  batch_size=32,\n",
    ")\n",
    "\n",
    "# Evaluate the model.\n",
    "model.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат получился чуть хуже, попробуем добавить еще нейронов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 10s 158us/step - loss: 0.3232 - accuracy: 0.8996\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.1630 - accuracy: 0.9495\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.1265 - accuracy: 0.9603\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.1063 - accuracy: 0.9665\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0907 - accuracy: 0.9714\n",
      "10000/10000 [==============================] - 2s 245us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09791141807287931, 0.968999981880188]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(100, activation='relu', input_shape=(784,)),\n",
    "  Dense(100, activation='relu'),\n",
    "  Dense(100, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=5,\n",
    "  batch_size=32,\n",
    ")\n",
    "\n",
    "# Evaluate the model.\n",
    "model.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уберем один слой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.3273 - accuracy: 0.9008\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.1600 - accuracy: 0.9501\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.1215 - accuracy: 0.9626\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.1012 - accuracy: 0.9686\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0877 - accuracy: 0.9722\n",
      "10000/10000 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09853620325699448, 0.9685999751091003]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(100, activation='relu', input_shape=(784,)),\n",
    "  Dense(100, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=5,\n",
    "  batch_size=32,\n",
    ")\n",
    "\n",
    "# Evaluate the model.\n",
    "model.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуемм добавить еще нейронов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.2989 - accuracy: 0.9084\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.1461 - accuracy: 0.9551\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.1104 - accuracy: 0.9657\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0921 - accuracy: 0.9710\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0783 - accuracy: 0.9742\n",
      "10000/10000 [==============================] - 2s 246us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09673015461941249, 0.9713000059127808]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(150, activation='relu', input_shape=(784,)),\n",
    "  Dense(150, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=5,\n",
    "  batch_size=32,\n",
    ")\n",
    "\n",
    "# Evaluate the model.\n",
    "model.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем добавить еще один слой и увеличить кол-во эпох."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.2959 - accuracy: 0.9073\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.1468 - accuracy: 0.9546\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.1123 - accuracy: 0.9646\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.0941 - accuracy: 0.9704\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0822 - accuracy: 0.9736\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0729 - accuracy: 0.9761\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.0663 - accuracy: 0.9793\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0574 - accuracy: 0.9814\n",
      "10000/10000 [==============================] - 0s 41us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09695492423631367, 0.9726999998092651]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(150, activation='relu', input_shape=(784,)),\n",
    "  Dense(150, activation='relu'),\n",
    "  Dense(150, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=8,\n",
    "  batch_size=32,\n",
    ")\n",
    "\n",
    "# Evaluate the model.\n",
    "model.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат получился лучше. По всей видимости увеличение кол-ва эпох нивелировало эффект затухающего градиента."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем еще раз увеличить все параметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.3016 - accuracy: 0.9058\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.1583 - accuracy: 0.9523\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.1223 - accuracy: 0.9627\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.1023 - accuracy: 0.9682\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.0890 - accuracy: 0.9723\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0779 - accuracy: 0.9749\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0696 - accuracy: 0.9785\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.0668 - accuracy: 0.9788\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0595 - accuracy: 0.9812\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0548 - accuracy: 0.9822\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0515 - accuracy: 0.9833\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.0497 - accuracy: 0.9849\n",
      "10000/10000 [==============================] - 0s 45us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10454919226564961, 0.9711999893188477]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(180, activation='relu', input_shape=(784,)),\n",
    "  Dense(180, activation='relu'),\n",
    "  Dense(180, activation='relu'),\n",
    "  Dense(180, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=12,\n",
    "  batch_size=32,\n",
    ")\n",
    "\n",
    "# Evaluate the model.\n",
    "model.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно 12 эпох слишком много и модель переоубчается, проверим это."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.3002 - accuracy: 0.9057\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 13s 218us/step - loss: 0.1561 - accuracy: 0.9516\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.1241 - accuracy: 0.9614\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.1032 - accuracy: 0.9683\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0918 - accuracy: 0.9709\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 0.0805 - accuracy: 0.9750\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0726 - accuracy: 0.9769\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 0.0677 - accuracy: 0.9789\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0585 - accuracy: 0.9811\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0582 - accuracy: 0.9814\n",
      "10000/10000 [==============================] - 0s 45us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08466160992686055, 0.9771000146865845]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(180, activation='relu', input_shape=(784,)),\n",
    "  Dense(180, activation='relu'),\n",
    "  Dense(180, activation='relu'),\n",
    "  Dense(180, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=10,\n",
    "  batch_size=32,\n",
    ")\n",
    "\n",
    "# Evaluate the model.\n",
    "model.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат получился чуть лучше. Попробуем добавить еще нейронов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.2964 - accuracy: 0.9071\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 0.1557 - accuracy: 0.9531\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 11s 192us/step - loss: 0.1212 - accuracy: 0.9634\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 14s 231us/step - loss: 0.1014 - accuracy: 0.9690\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 13s 225us/step - loss: 0.0895 - accuracy: 0.9724\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 0.0769 - accuracy: 0.9762\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 0.0705 - accuracy: 0.9779\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0681 - accuracy: 0.9789\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 15s 242us/step - loss: 0.0599 - accuracy: 0.9805\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 14s 234us/step - loss: 0.0573 - accuracy: 0.9823\n",
      "10000/10000 [==============================] - 1s 54us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0924060961878713, 0.9757999777793884]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(220, activation='relu', input_shape=(784,)),\n",
    "  Dense(220, activation='relu'),\n",
    "  Dense(220, activation='relu'),\n",
    "  Dense(220, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=10,\n",
    "  batch_size=32,\n",
    ")\n",
    "\n",
    "# Evaluate the model.\n",
    "model.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 17s 283us/step - loss: 0.3097 - accuracy: 0.9033\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 16s 267us/step - loss: 0.1631 - accuracy: 0.9513\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 0.1329 - accuracy: 0.9606\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 17s 291us/step - loss: 0.1086 - accuracy: 0.9674\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 17s 290us/step - loss: 0.0969 - accuracy: 0.9714\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 15s 258us/step - loss: 0.0848 - accuracy: 0.9743\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 15s 250us/step - loss: 0.0791 - accuracy: 0.9761\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 16s 269us/step - loss: 0.0702 - accuracy: 0.9791\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 15s 251us/step - loss: 0.0674 - accuracy: 0.9800\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 15s 249us/step - loss: 0.0599 - accuracy: 0.9823\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 16s 265us/step - loss: 0.0588 - accuracy: 0.9826\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 16s 274us/step - loss: 0.0554 - accuracy: 0.9831\n",
      "10000/10000 [==============================] - 5s 469us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11230551293905337, 0.9758999943733215]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(250, activation='relu', input_shape=(784,)),\n",
    "  Dense(250, activation='relu'),\n",
    "  Dense(250, activation='relu'),\n",
    "  Dense(250, activation='relu'),\n",
    "  Dense(250, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=12,\n",
    "  batch_size=32,\n",
    ")\n",
    "\n",
    "# Evaluate the model.\n",
    "model.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 14s 230us/step - loss: 0.3126 - accuracy: 0.9013\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 15s 247us/step - loss: 0.1657 - accuracy: 0.9504\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 14s 238us/step - loss: 0.1326 - accuracy: 0.9599\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 15s 253us/step - loss: 0.1100 - accuracy: 0.9669\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 15s 247us/step - loss: 0.0970 - accuracy: 0.9703\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 15s 252us/step - loss: 0.0846 - accuracy: 0.9742\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 14s 230us/step - loss: 0.0789 - accuracy: 0.9762\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 14s 237us/step - loss: 0.0707 - accuracy: 0.9783\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 14s 239us/step - loss: 0.0670 - accuracy: 0.9797\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 14s 241us/step - loss: 0.0597 - accuracy: 0.9818\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 15s 250us/step - loss: 0.0553 - accuracy: 0.9831\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.0564 - accuracy: 0.9830\n",
      "10000/10000 [==============================] - 3s 256us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08670836529053703, 0.9775000214576721]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(180, activation='relu', input_shape=(784,)),\n",
    "  Dense(180, activation='relu'),\n",
    "  Dense(180, activation='relu'),\n",
    "  Dense(180, activation='relu'),\n",
    "  Dense(180, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=12,\n",
    "  batch_size=32,\n",
    ")\n",
    "\n",
    "# Evaluate the model.\n",
    "model.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "60000/60000 [==============================] - 16s 264us/step - loss: 0.3097 - accuracy: 0.9025\n",
      "Epoch 2/11\n",
      "60000/60000 [==============================] - 16s 265us/step - loss: 0.1637 - accuracy: 0.9502\n",
      "Epoch 3/11\n",
      "60000/60000 [==============================] - 15s 246us/step - loss: 0.1328 - accuracy: 0.9594\n",
      "Epoch 4/11\n",
      "60000/60000 [==============================] - 15s 247us/step - loss: 0.1132 - accuracy: 0.9659\n",
      "Epoch 5/11\n",
      "60000/60000 [==============================] - 15s 255us/step - loss: 0.0956 - accuracy: 0.9713\n",
      "Epoch 6/11\n",
      "60000/60000 [==============================] - 14s 241us/step - loss: 0.0905 - accuracy: 0.9726\n",
      "Epoch 7/11\n",
      "60000/60000 [==============================] - 15s 257us/step - loss: 0.0765 - accuracy: 0.9766\n",
      "Epoch 8/11\n",
      "60000/60000 [==============================] - 16s 262us/step - loss: 0.0691 - accuracy: 0.9788\n",
      "Epoch 9/11\n",
      "60000/60000 [==============================] - 15s 257us/step - loss: 0.0666 - accuracy: 0.9797\n",
      "Epoch 10/11\n",
      "60000/60000 [==============================] - 15s 254us/step - loss: 0.0609 - accuracy: 0.9813\n",
      "Epoch 11/11\n",
      "60000/60000 [==============================] - 15s 252us/step - loss: 0.0569 - accuracy: 0.9830\n",
      "10000/10000 [==============================] - 3s 289us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10209386850666488, 0.9718999862670898]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(180, activation='relu', input_shape=(784,)),\n",
    "  Dense(180, activation='relu'),\n",
    "  Dense(180, activation='relu'),\n",
    "  Dense(180, activation='relu'),\n",
    "  Dense(180, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=11,\n",
    "  batch_size=32,\n",
    ")\n",
    "\n",
    "# Evaluate the model.\n",
    "model.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "60000/60000 [==============================] - 16s 275us/step - loss: 0.3295 - accuracy: 0.8970\n",
      "Epoch 2/14\n",
      "60000/60000 [==============================] - 16s 269us/step - loss: 0.1793 - accuracy: 0.9471\n",
      "Epoch 3/14\n",
      "60000/60000 [==============================] - 16s 267us/step - loss: 0.1422 - accuracy: 0.9582\n",
      "Epoch 4/14\n",
      "60000/60000 [==============================] - 15s 245us/step - loss: 0.1184 - accuracy: 0.9646\n",
      "Epoch 5/14\n",
      "60000/60000 [==============================] - 14s 230us/step - loss: 0.1058 - accuracy: 0.9692\n",
      "Epoch 6/14\n",
      "60000/60000 [==============================] - 15s 248us/step - loss: 0.0925 - accuracy: 0.9728\n",
      "Epoch 7/14\n",
      "60000/60000 [==============================] - 15s 256us/step - loss: 0.0842 - accuracy: 0.9750\n",
      "Epoch 8/14\n",
      "60000/60000 [==============================] - 15s 246us/step - loss: 0.0759 - accuracy: 0.9774\n",
      "Epoch 9/14\n",
      "60000/60000 [==============================] - 15s 247us/step - loss: 0.0716 - accuracy: 0.9793\n",
      "Epoch 10/14\n",
      "60000/60000 [==============================] - 16s 263us/step - loss: 0.0677 - accuracy: 0.9797\n",
      "Epoch 11/14\n",
      "60000/60000 [==============================] - 15s 248us/step - loss: 0.0630 - accuracy: 0.9811\n",
      "Epoch 12/14\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 0.0549 - accuracy: 0.9841\n",
      "Epoch 13/14\n",
      "60000/60000 [==============================] - 16s 263us/step - loss: 0.0602 - accuracy: 0.9826\n",
      "Epoch 14/14\n",
      "60000/60000 [==============================] - 16s 270us/step - loss: 0.0511 - accuracy: 0.9848\n",
      "10000/10000 [==============================] - 1s 81us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08889369516318621, 0.9796000123023987]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(180, activation='relu', input_shape=(784,)),\n",
    "  Dense(180, activation='relu'),\n",
    "  Dense(180, activation='relu'),\n",
    "  Dense(180, activation='relu'),\n",
    "  Dense(180, activation='relu'),\n",
    "  Dense(180, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=14,\n",
    "  batch_size=32,\n",
    ")\n",
    "\n",
    "# Evaluate the model.\n",
    "model.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге лучший результат с точностью 0.9796 мы получили на нейросети с 7-ю слоями по 180 нейронов в каждом, кроме последнего и с 14 эпохами обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно что некоторые отличия результатов это результат разных начальных весов. Увидели тенденцию на увеличение точности с ростом кол-ва слоев и нейронов в них. Модель с большим количеством слоев сложнее обучать. Итого разница между лучшей и худшей моделью оказалась чуть больше 2%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
