{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from facenet_pytorch import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGRecognition(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = self.conv_block(1, 32, pool=False)\n",
    "        self.conv2 = self.conv_block(32, 32, pool=True)\n",
    "        self.conv3 = self.conv_block(32, 64, pool=True)\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        self.dense = nn.Sequential(nn.Flatten(), nn.Linear(64*6*6, 256), nn.ReLU(inplace=True), \n",
    "                                  nn.Linear(256, 10), nn.Softmax(dim=1))\n",
    "        \n",
    "    @staticmethod\n",
    "    def conv_block(in_feat, out_feat, pool=False):\n",
    "        layers = [nn.Conv2d(in_feat, out_feat, kernel_size=3), nn.ReLU(inplace=True)]\n",
    "        if pool:\n",
    "            layers.append(nn.MaxPool2d(kernel_size=3))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.drop(out)\n",
    "        #print(out.size())\n",
    "        out = self.dense(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceAndHandDetector():\n",
    "    \n",
    "    def __init__(self, mtcnn, hg_model):\n",
    "        self.mtcnn = mtcnn\n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.hg_model = hg_model.to(self.device)\n",
    "        self.hg_model.load_state_dict(torch.load('./Models/Hand_Gesture_Recognition.pth'))\n",
    "        self.hg_model.eval()\n",
    "        \n",
    "        \n",
    "    def _draw(self, frame, boxes, probs, landmarks):\n",
    "        try:\n",
    "            for box, prob, ld in zip(boxes, probs, landmarks):\n",
    "                # Рисуем обрамляющий прямоугольник лица на кадре\n",
    "                cv2.rectangle(frame,\n",
    "                              (box[0], box[1]),\n",
    "                              (box[2], box[3]),\n",
    "                              (0, 0, 255),\n",
    "                              thickness=2)\n",
    "\n",
    "                # Рисуем особенные точки\n",
    "                cv2.circle(frame, tuple(ld[0]), 5, (0, 0, 255), -1)\n",
    "                cv2.circle(frame, tuple(ld[1]), 5, (0, 0, 255), -1)\n",
    "                cv2.circle(frame, tuple(ld[2]), 5, (0, 0, 255), -1)\n",
    "                cv2.circle(frame, tuple(ld[3]), 5, (0, 0, 255), -1)\n",
    "                cv2.circle(frame, tuple(ld[4]), 5, (0, 0, 255), -1)\n",
    "        except:\n",
    "            print('Something wrong in draw function!')\n",
    "\n",
    "        return frame\n",
    "    \n",
    "    @staticmethod\n",
    "    def digit_to_classname(digit):\n",
    "        cats = [\"palm\", 'l','fist','fist_moved','thumb','index','ok','palm_moved','c','down']\n",
    "        return cats[digit]\n",
    "    \n",
    "    def run(self):\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            try:\n",
    "                # детектируем расположение лица на кадре, вероятности на сколько это лицо\n",
    "                # и особенные точки лица\n",
    "                boxes, probs, landmarks = self.mtcnn.detect(frame, landmarks=True)\n",
    "                if isinstance(boxes, np.ndarray):\n",
    "                    # Рисуем на кадре рамку для лица, если на кадре лицо.\n",
    "                    self._draw(frame, boxes, probs, landmarks)\n",
    "                else:\n",
    "                    #если на кадре не лицо, пытаемся определить жест.\n",
    "                    hand = cv2.resize(frame, (64, 64))\n",
    "                    hand = cv2.cvtColor(hand, cv2.COLOR_BGR2GRAY)\n",
    "                    torch_hand = torch.from_numpy(hand).unsqueeze(0).to(self.device).float()\n",
    "                    gesture_probs = self.hg_model(torch_hand[None, ...])\n",
    "                    gesture = self.digit_to_classname(gesture_probs.argmax())\n",
    "                    h, w = frame.shape[:2]\n",
    "                    cv2.putText(frame, gesture, (w//2, h), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f'Something wrong in main cycle! {e}')\n",
    "\n",
    "            # Показываем кадр в окне, и назвываем его(окно) - 'Face Detection'\n",
    "            cv2.imshow('Face Detection', frame)\n",
    "            \n",
    "            # Функция, которая проверяет нажатие на клавишу 'q'\n",
    "            # Если нажатие произошло - выход из цикла. Конец работы приложения\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "                \n",
    "        # Очищаем все объекты opencv, что мы создали\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-3fad3ffda3ea>:15: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  cv2.rectangle(frame,\n",
      "<ipython-input-37-3fad3ffda3ea>:22: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  cv2.circle(frame, tuple(ld[0]), 5, (0, 0, 255), -1)\n",
      "<ipython-input-37-3fad3ffda3ea>:23: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  cv2.circle(frame, tuple(ld[1]), 5, (0, 0, 255), -1)\n",
      "<ipython-input-37-3fad3ffda3ea>:24: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  cv2.circle(frame, tuple(ld[2]), 5, (0, 0, 255), -1)\n",
      "<ipython-input-37-3fad3ffda3ea>:25: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  cv2.circle(frame, tuple(ld[3]), 5, (0, 0, 255), -1)\n",
      "<ipython-input-37-3fad3ffda3ea>:26: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  cv2.circle(frame, tuple(ld[4]), 5, (0, 0, 255), -1)\n"
     ]
    }
   ],
   "source": [
    "mtcnn = MTCNN()\n",
    "hg_model = HGRecognition()\n",
    "fd = FaceAndHandDetector(mtcnn, hg_model)\n",
    "fd.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
